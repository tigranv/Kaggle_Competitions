{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "from skimage import io\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from skimage import io\n",
    "from skimage import measure \n",
    "from skimage import feature\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters import rank\n",
    "from skimage import exposure\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "marks = pd.read_csv('D:/Kaggle/train_ship_segmentations.csv') # Markers for ships\n",
    "images = os.listdir('D:/Kaggle/train_images') # Images for training\n",
    "test_marks = pd.read_csv('D:/Kaggle/test_ship_segmentations.csv')\n",
    "test_images = os.listdir('D:/Kaggle/test_images')\n",
    "os.chdir(\"D:/Kaggle/train_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENT_BRIGHTNESS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_part(pic):\n",
    "    '''\n",
    "    Function that encodes mask for single ship from .csv entry into numpy matrix\n",
    "    '''\n",
    "    back = np.zeros(768**2)\n",
    "    starts = pic.split()[0::2]\n",
    "    lens = pic.split()[1::2]\n",
    "    for i in range(len(lens)):\n",
    "        back[(int(starts[i])-1):(int(starts[i])-1+int(lens[i]))] = 1\n",
    "    return np.reshape(back, (768, 768, 1))\n",
    "\n",
    "def is_empty(key):\n",
    "    '''\n",
    "    Function that checks if there is a ship in image\n",
    "    '''\n",
    "    df = train_data[train_data['ImageId'] == key].iloc[:,1]\n",
    "    if len(df) == 1 and type(df.iloc[0]) != str and np.isnan(df.iloc[0]):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def masks_all(key):\n",
    "    '''\n",
    "    Merges together all the ship markers corresponding to a single image\n",
    "    '''\n",
    "    df = train_data[train_data['ImageId'] == key].iloc[:,1]\n",
    "    masks= np.zeros((768,768,1))\n",
    "    if is_empty(key):\n",
    "        return masks\n",
    "    else:\n",
    "        for i in range(len(df)):\n",
    "            masks += mask_part(df.iloc[i])\n",
    "        return np.transpose(masks, (1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "marks['ships'] = marks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "train_data = marks[marks[\"ships\"]!=0]\n",
    "train_ids = list(train_data[\"ImageId\"])\n",
    "no_ships_train = list(set(images) & set(train_ids))\n",
    "train_images_ids = list(set(no_ships_train) & set(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_marks['ships'] = test_marks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "test_data = test_marks[test_marks[\"ships\"]!=0]\n",
    "test_ids = list(test_data[\"ImageId\"])\n",
    "no_ships_test = list(set(test_images) & set(test_ids))\n",
    "test_images_ids = list(set(no_ships_test) & set(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util.montage import montage2d as montage\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gen_clear_data(ids, batch_size):    \n",
    "    X = np.zeros((batch_size, 768, 768, 3))\n",
    "    Y = np.zeros((batch_size, 768, 768, 1))\n",
    "    while True:\n",
    "        print(\"hello\")\n",
    "        for i in range(batch_size):\n",
    "            index = np.random.choice(len(ids))\n",
    "            print(ids[index])\n",
    "            X[i] = io.imread(ids[index])/255.0\n",
    "            Y[i] = masks_all(ids[index])\n",
    "        yield X,Y\n",
    "            \n",
    "def Gen_aug_data(batch, batch_size, seed = None):\n",
    "\n",
    "    dg_args = dict(featurewise_center = False, \n",
    "              samplewise_center = False,\n",
    "              rotation_range = 15, \n",
    "              width_shift_range = 0.1, \n",
    "              height_shift_range = 0.1, \n",
    "              shear_range = 0.01,\n",
    "              zoom_range = [0.9, 1.25],  \n",
    "              horizontal_flip = True, \n",
    "              vertical_flip = True,\n",
    "              fill_mode = 'reflect',\n",
    "              data_format = 'channels_last')\n",
    "    if AUGMENT_BRIGHTNESS:\n",
    "        dg_args[' brightness_range'] = [0.5, 1.5]\n",
    "    image_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "    if AUGMENT_BRIGHTNESS:\n",
    "        dg_args.pop('brightness_range')\n",
    "    label_gen = ImageDataGenerator(**dg_args)\n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    for i in range(batch_size):\n",
    "        seed = np.random.choice(range(9999))\n",
    "        aug_x = image_gen.flow(255*batch[0], batch_size = batch_size, seed = seed, shuffle=True)\n",
    "        aug_y = label_gen.flow(batch[1],batch_size = batch_size, seed = seed, shuffle=True)\n",
    "\n",
    "        yield next(aug_x)/255.0, next(aug_y)\n",
    "\n",
    "class Generator():\n",
    "    def __init__(self, ids, batch_size,augmentation = False, add_feautures = False):\n",
    "        self.ids = ids\n",
    "        self.batch_size = batch_size\n",
    "        self.augmentation = augmentation\n",
    "        self.add_feautures = add_feautures\n",
    "        self.AUGMENT_BRIGHTNESS = False\n",
    "        self.batch_ids = []\n",
    "           \n",
    "    def Data_generator(self):\n",
    "        while True:\n",
    "            if self.augmentation == False:\n",
    "                gen = Gen_clear_data(self.ids, self.batch_size)\n",
    "                yield next(gen)\n",
    "            elif self.augmentation == True:\n",
    "                gen = Gen_clear_data(self.ids,self.batch_size)\n",
    "                data = next(gen)\n",
    "                gen_aug_data = Gen_aug_data(data,self.batch_size)\n",
    "                yield next(gen_aug_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddd = Gen_clear_data(train_ids, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "663b10d81.jpg\n",
      "e3169b14a.jpg\n",
      "11ef28b6d.jpg\n",
      "hello\n",
      "be3abb90c.jpg\n",
      "69bd1b7dc.jpg\n",
      "5f92de2d0.jpg\n",
      "hello\n",
      "b25bc8ca4.jpg\n",
      "40951b370.jpg\n",
      "cdcea0e9f.jpg\n",
      "hello\n",
      "b418edd67.jpg\n",
      "345c4036d.jpg\n",
      "1e4722857.jpg\n",
      "hello\n",
      "54f26faa5.jpg\n",
      "8421eaa36.jpg\n",
      "d36d886a3.jpg\n",
      "hello\n",
      "d6bc1a321.jpg\n",
      "f3bb38ccc.jpg\n",
      "706ef5f93.jpg\n",
      "hello\n",
      "8dbce7878.jpg\n",
      "e45e9beef.jpg\n",
      "d4a41ec48.jpg\n",
      "hello\n",
      "96b0a4657.jpg\n",
      "f6f75def4.jpg\n",
      "4b510d261.jpg\n",
      "hello\n",
      "d8f776013.jpg\n",
      "6046848af.jpg\n",
      "c65c40baa.jpg\n",
      "hello\n",
      "e44ce8314.jpg\n",
      "ce536a86a.jpg\n",
      "74acc425d.jpg\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    \n",
    "    tup = next(ddd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tup[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x, t_y = a[0], a[1]\n",
    "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n",
    "# only keep first 9 samples to examine in detail\n",
    "t_x = t_x[:9]\n",
    "t_y = t_y[:9]\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "ax1.imshow(montage_rgb(t_x), cmap='gray')\n",
    "ax1.set_title('images')\n",
    "ax2.imshow(montage(t_y[:, :, :, 0]), cmap='gray_r')\n",
    "ax2.set_title('ships')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection over Union for Objects\n",
    "def IoU(y_true, y_pred, tresh=1e-10):\n",
    "    Intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    Union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3]) - Intersection\n",
    "    return K.mean( (Intersection + tresh) / (Union + tresh), axis=0)\n",
    "# Intersection over Union for Background\n",
    "def back_IoU(y_true, y_pred):\n",
    "    return IoU(1-y_true, 1-y_pred)\n",
    "# Loss function\n",
    "def IoU_loss(in_gt, in_pred):\n",
    "    #return 2 - back_IoU(in_gt, in_pred) - IoU(in_gt, in_pred)\n",
    "    return 1 - IoU(in_gt, in_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((768, 768, 3))\n",
    "\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
    "\n",
    "u5 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c4)\n",
    "u5 = concatenate([u5, c3])\n",
    "c5 = Conv2D(32, (3, 3), activation='relu', padding='same') (u5)\n",
    "c5 = Conv2D(32, (3, 3), activation='relu', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c2])\n",
    "c6 = Conv2D(16, (3, 3), activation='relu', padding='same') (u6)\n",
    "c6 = Conv2D(16, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c1], axis=3)\n",
    "c7 = Conv2D(8, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = Conv2D(8, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c7)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer=\"adam\", loss= IoU_loss, metrics=[IoU, back_IoU])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gen = Generator(train_images_ids,batch_size=3, augmentation=False)\n",
    "generator = Gen.Data_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit_generator(generator=generator,steps_per_epoch=10,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
