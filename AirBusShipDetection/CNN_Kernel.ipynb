{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "marks = pd.read_csv('D:/Kaggle/train_ship_segmentations.csv') # Markers for ships\n",
    "images = os.listdir('D:/Kaggle/train_images') # Images for training\n",
    "os.chdir(\"D:/Kaggle/train_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_part(pic):\n",
    "    '''\n",
    "    Function that encodes mask for single ship from .csv entry into numpy matrix\n",
    "    '''\n",
    "    back = np.zeros(768**2)\n",
    "    starts = pic.split()[0::2]\n",
    "    lens = pic.split()[1::2]\n",
    "    for i in range(len(lens)):\n",
    "        back[(int(starts[i])-1):(int(starts[i])-1+int(lens[i]))] = 1\n",
    "    return np.reshape(back, (768, 768, 1))\n",
    "\n",
    "def is_empty(key):\n",
    "    '''\n",
    "    Function that checks if there is a ship in image\n",
    "    '''\n",
    "    df = marks[marks['ImageId'] == key].iloc[:,1]\n",
    "    if len(df) == 1 and type(df.iloc[0]) != str and np.isnan(df.iloc[0]):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def masks_all(key):\n",
    "    '''\n",
    "    Merges together all the ship markers corresponding to a single image\n",
    "    '''\n",
    "    df = marks[marks['ImageId'] == key].iloc[:,1]\n",
    "    masks= np.zeros((768,768,1))\n",
    "    if is_empty(key):\n",
    "        return masks\n",
    "    else:\n",
    "        for i in range(len(df)):\n",
    "            masks += mask_part(df.iloc[i])\n",
    "        return np.transpose(masks, (1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X, Y):\n",
    "    '''\n",
    "    Function for augmenting images. \n",
    "    It takes original image and corresponding mask and performs the\n",
    "    same flipping and rotation transforamtions on both in order to \n",
    "    perserve the overlapping of ships and their masks\n",
    "    '''\n",
    "# add noise:\n",
    "    x = np.copy(X)\n",
    "    y = np.copy(Y)\n",
    "    x[:,:,0] = x[:,:,0] + np.random.normal(loc=0.0, scale=0.01, size=(768,768))\n",
    "    x[:,:,1] = x[:,:,1] + np.random.normal(loc=0.0, scale=0.01, size=(768,768))\n",
    "    x[:,:,2] = x[:,:,2] + np.random.normal(loc=0.0, scale=0.01, size=(768,768))\n",
    "    # Adding Gaussian noise on each rgb channel; this way we will NEVER get two completely same images.\n",
    "    # Note that this transformation is not performed on Y \n",
    "    x[np.where(x<0)] = 0\n",
    "    x[np.where(x>1)] = 1\n",
    "# axes swap:\n",
    "    if np.random.rand()<0.5: # 0.5 chances for this transformation to occur (same for two below)\n",
    "        x = np.swapaxes(x, 0,1)\n",
    "        y = np.swapaxes(y, 0,1)\n",
    "# vertical flip:\n",
    "    if np.random.rand()<0.5:\n",
    "        x = np.flip(x, 0)\n",
    "        y = np.flip(y, 0)\n",
    "# horizontal flip:\n",
    "    if np.random.rand()<0.5:\n",
    "        x = np.flip(x, 1)\n",
    "        y = np.flip(y, 1)\n",
    "    return x, y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(files, batch_size):\n",
    "    '''\n",
    "    Creates batches of images and masks in order to feed them to NN\n",
    "    '''\n",
    "    X = np.zeros((batch_size, 768, 768, 3))\n",
    "    Y = np.zeros((batch_size, 768, 768, 1)) # I add 1 here to get 4D batch\n",
    "    for i in range(batch_size):\n",
    "        ship = np.random.choice(files)\n",
    "        X[i] = (io.imread(ship))/255.0 # Original images are in 0-255 range, I want it in 0-1\n",
    "        Y[i]= masks_all(ship)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generator(files, batch_size):\n",
    "    '''\n",
    "    Generates batches of images and corresponding masks\n",
    "    '''\n",
    "    while True:\n",
    "        X, Y = make_batch(files, batch_size)\n",
    "        for i in range(batch_size):\n",
    "            X[i], Y[i] = transform(X[i], Y[i])\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection over Union for Objects\n",
    "def IoU(y_true, y_pred, tresh=1e-10):\n",
    "    Intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    Union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3]) - Intersection\n",
    "    return K.mean( (Intersection + tresh) / (Union + tresh), axis=0)\n",
    "# Intersection over Union for Background\n",
    "def back_IoU(y_true, y_pred):\n",
    "    return IoU(1-y_true, 1-y_pred)\n",
    "# Loss function\n",
    "def IoU_loss(in_gt, in_pred):\n",
    "    #return 2 - back_IoU(in_gt, in_pred) - IoU(in_gt, in_pred)\n",
    "    return 1 - IoU(in_gt, in_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = Input((768, 768, 3))\n",
    "\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (inputs)\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
    "\n",
    "u5 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c4)\n",
    "u5 = concatenate([u5, c3])\n",
    "c5 = Conv2D(32, (3, 3), activation='relu', padding='same') (u5)\n",
    "c5 = Conv2D(32, (3, 3), activation='relu', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c2])\n",
    "c6 = Conv2D(16, (3, 3), activation='relu', padding='same') (u6)\n",
    "c6 = Conv2D(16, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c1], axis=3)\n",
    "c7 = Conv2D(8, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = Conv2D(8, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c7)\n",
    "\n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss= IoU_loss, metrics=[IoU, back_IoU])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_memory_usage(batch_size, model):\n",
    "    import numpy as np\n",
    "    from keras import backend as K\n",
    "\n",
    "    shapes_mem_count = 0\n",
    "    for l in model.layers:\n",
    "        single_layer_mem = 1\n",
    "        for s in l.output_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([K.count_params(p) for p in set(model.trainable_weights)])\n",
    "    non_trainable_count = np.sum([K.count_params(p) for p in set(model.non_trainable_weights)])\n",
    "\n",
    "    total_memory = 4.0*batch_size*(shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3)\n",
    "    return gbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_memory_usage(50, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = model.fit_generator(Generator(images, batch_size = 200), steps_per_epoch = 500, epochs = 30)\n",
    "results = model.fit_generator(Generator(images[:10], batch_size = 5), steps_per_epoch = 2, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
